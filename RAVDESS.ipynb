{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa numpy pandas scikit-learn matplotlib tensorflow sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X: 2880\n",
      "Length of y: 2880\n",
      "Shape of X: (2880, 40)\n",
      "Shape of y_encoded: (2880,)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Path to the RAVDESS dataset folder\n",
    "dataset_path = r\"C:\\Users\\Hp\\Downloads\\RAVDESS\"\n",
    "\n",
    "# Emotion labels dictionary\n",
    "emotion_labels = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Lists to store extracted features and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through all audio files in the dataset\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            # Extract emotion from the filename (3rd field in the name)\n",
    "            file_parts = file.split('-')\n",
    "            emotion_code = file_parts[2]  # Third part of the filename is the emotion code\n",
    "\n",
    "            # Check if the emotion code is valid\n",
    "            if emotion_code in emotion_labels:\n",
    "                emotion = emotion_labels[emotion_code]\n",
    "\n",
    "                # Load audio file using librosa\n",
    "                file_path = os.path.join(root, file)\n",
    "                y_audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                # Extract MFCC features\n",
    "                mfccs = librosa.feature.mfcc(y=y_audio, sr=sr, n_mfcc=40)\n",
    "                mfccs_mean = np.mean(mfccs.T, axis=0)  # Mean of MFCCs\n",
    "\n",
    "                # Append features and label\n",
    "                X.append(mfccs_mean)\n",
    "                y.append(emotion)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Print the sizes of X and y to check if they are empty\n",
    "print(f\"Length of X: {len(X)}\")\n",
    "print(f\"Length of y: {len(y)}\")\n",
    "\n",
    "# Encode emotion labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Print the shapes of X and y_encoded\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y_encoded: {y_encoded.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.1540 - loss: 2.0732 - val_accuracy: 0.2361 - val_loss: 1.9571\n",
      "Epoch 2/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.2282 - loss: 1.9709 - val_accuracy: 0.2674 - val_loss: 1.8995\n",
      "Epoch 3/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.2693 - loss: 1.9112 - val_accuracy: 0.3021 - val_loss: 1.8567\n",
      "Epoch 4/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.2823 - loss: 1.8782 - val_accuracy: 0.3142 - val_loss: 1.7928\n",
      "Epoch 5/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.3000 - loss: 1.8110 - val_accuracy: 0.3142 - val_loss: 1.7768\n",
      "Epoch 6/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.2920 - loss: 1.8102 - val_accuracy: 0.2969 - val_loss: 1.7583\n",
      "Epoch 7/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.3057 - loss: 1.7932 - val_accuracy: 0.3177 - val_loss: 1.7590\n",
      "Epoch 8/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3174 - loss: 1.7668 - val_accuracy: 0.3316 - val_loss: 1.7314\n",
      "Epoch 9/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.3228 - loss: 1.7233 - val_accuracy: 0.3229 - val_loss: 1.7082\n",
      "Epoch 10/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3253 - loss: 1.7015 - val_accuracy: 0.3507 - val_loss: 1.6959\n",
      "Epoch 11/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.3486 - loss: 1.7024 - val_accuracy: 0.3125 - val_loss: 1.6748\n",
      "Epoch 12/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3551 - loss: 1.6849 - val_accuracy: 0.3646 - val_loss: 1.6514\n",
      "Epoch 13/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.3705 - loss: 1.6373 - val_accuracy: 0.3559 - val_loss: 1.6646\n",
      "Epoch 14/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.3606 - loss: 1.6198 - val_accuracy: 0.3663 - val_loss: 1.6560\n",
      "Epoch 15/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.3633 - loss: 1.6439 - val_accuracy: 0.3542 - val_loss: 1.6412\n",
      "Epoch 16/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.3829 - loss: 1.5894 - val_accuracy: 0.3264 - val_loss: 1.6854\n",
      "Epoch 17/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.3978 - loss: 1.5707 - val_accuracy: 0.4097 - val_loss: 1.5910\n",
      "Epoch 18/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4195 - loss: 1.5337 - val_accuracy: 0.3646 - val_loss: 1.5917\n",
      "Epoch 19/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3892 - loss: 1.5773 - val_accuracy: 0.3819 - val_loss: 1.6061\n",
      "Epoch 20/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4305 - loss: 1.4889 - val_accuracy: 0.4062 - val_loss: 1.5683\n",
      "Epoch 21/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.3894 - loss: 1.5553 - val_accuracy: 0.3837 - val_loss: 1.5680\n",
      "Epoch 22/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4186 - loss: 1.5115 - val_accuracy: 0.3976 - val_loss: 1.5593\n",
      "Epoch 23/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4249 - loss: 1.4940 - val_accuracy: 0.4080 - val_loss: 1.5130\n",
      "Epoch 24/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4587 - loss: 1.4292 - val_accuracy: 0.4045 - val_loss: 1.5454\n",
      "Epoch 25/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4363 - loss: 1.4425 - val_accuracy: 0.4045 - val_loss: 1.5774\n",
      "Epoch 26/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.4479 - loss: 1.4229 - val_accuracy: 0.4288 - val_loss: 1.5067\n",
      "Epoch 27/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4652 - loss: 1.3754 - val_accuracy: 0.3941 - val_loss: 1.5403\n",
      "Epoch 28/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.4549 - loss: 1.4088 - val_accuracy: 0.4323 - val_loss: 1.4822\n",
      "Epoch 29/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4583 - loss: 1.3818 - val_accuracy: 0.4149 - val_loss: 1.4774\n",
      "Epoch 30/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4676 - loss: 1.3771 - val_accuracy: 0.4201 - val_loss: 1.4860\n",
      "Epoch 31/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4834 - loss: 1.3610 - val_accuracy: 0.4306 - val_loss: 1.4658\n",
      "Epoch 32/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4734 - loss: 1.3320 - val_accuracy: 0.3976 - val_loss: 1.5285\n",
      "Epoch 33/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4999 - loss: 1.3352 - val_accuracy: 0.3976 - val_loss: 1.5002\n",
      "Epoch 34/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4958 - loss: 1.3292 - val_accuracy: 0.4392 - val_loss: 1.4350\n",
      "Epoch 35/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5054 - loss: 1.2984 - val_accuracy: 0.4340 - val_loss: 1.4286\n",
      "Epoch 36/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5137 - loss: 1.2755 - val_accuracy: 0.4427 - val_loss: 1.4885\n",
      "Epoch 37/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5157 - loss: 1.2413 - val_accuracy: 0.4531 - val_loss: 1.4270\n",
      "Epoch 38/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5338 - loss: 1.2169 - val_accuracy: 0.4705 - val_loss: 1.4042\n",
      "Epoch 39/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5495 - loss: 1.1844 - val_accuracy: 0.4583 - val_loss: 1.4060\n",
      "Epoch 40/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5384 - loss: 1.2081 - val_accuracy: 0.4688 - val_loss: 1.4073\n",
      "Epoch 41/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5314 - loss: 1.2156 - val_accuracy: 0.4670 - val_loss: 1.3847\n",
      "Epoch 42/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5388 - loss: 1.2119 - val_accuracy: 0.5035 - val_loss: 1.3323\n",
      "Epoch 43/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5342 - loss: 1.2056 - val_accuracy: 0.4740 - val_loss: 1.3747\n",
      "Epoch 44/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5396 - loss: 1.1403 - val_accuracy: 0.4896 - val_loss: 1.3780\n",
      "Epoch 45/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6004 - loss: 1.0692 - val_accuracy: 0.4878 - val_loss: 1.3964\n",
      "Epoch 46/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5786 - loss: 1.0737 - val_accuracy: 0.5052 - val_loss: 1.3311\n",
      "Epoch 47/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5814 - loss: 1.0988 - val_accuracy: 0.4826 - val_loss: 1.3461\n",
      "Epoch 48/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.6130 - loss: 1.0428 - val_accuracy: 0.5174 - val_loss: 1.3160\n",
      "Epoch 49/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6262 - loss: 0.9877 - val_accuracy: 0.5122 - val_loss: 1.3642\n",
      "Epoch 50/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6184 - loss: 1.0352 - val_accuracy: 0.5365 - val_loss: 1.2844\n",
      "Epoch 51/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6116 - loss: 0.9918 - val_accuracy: 0.5226 - val_loss: 1.4012\n",
      "Epoch 52/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6335 - loss: 1.0481 - val_accuracy: 0.5469 - val_loss: 1.2640\n",
      "Epoch 53/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6532 - loss: 0.9369 - val_accuracy: 0.5243 - val_loss: 1.3360\n",
      "Epoch 54/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6359 - loss: 0.9591 - val_accuracy: 0.5590 - val_loss: 1.2600\n",
      "Epoch 55/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6539 - loss: 0.8689 - val_accuracy: 0.5642 - val_loss: 1.2222\n",
      "Epoch 56/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6553 - loss: 0.9144 - val_accuracy: 0.5799 - val_loss: 1.2409\n",
      "Epoch 57/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6637 - loss: 0.8930 - val_accuracy: 0.6059 - val_loss: 1.1947\n",
      "Epoch 58/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6236 - loss: 0.9887 - val_accuracy: 0.5694 - val_loss: 1.2636\n",
      "Epoch 59/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6578 - loss: 0.8715 - val_accuracy: 0.5938 - val_loss: 1.1980\n",
      "Epoch 60/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6738 - loss: 0.8818 - val_accuracy: 0.5885 - val_loss: 1.1904\n",
      "Epoch 61/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6863 - loss: 0.8203 - val_accuracy: 0.6163 - val_loss: 1.1652\n",
      "Epoch 62/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7215 - loss: 0.7655 - val_accuracy: 0.6372 - val_loss: 1.1258\n",
      "Epoch 63/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7280 - loss: 0.7507 - val_accuracy: 0.6285 - val_loss: 1.1307\n",
      "Epoch 64/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7174 - loss: 0.7540 - val_accuracy: 0.6163 - val_loss: 1.1183\n",
      "Epoch 65/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7160 - loss: 0.7458 - val_accuracy: 0.6302 - val_loss: 1.1501\n",
      "Epoch 66/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7402 - loss: 0.6944 - val_accuracy: 0.6354 - val_loss: 1.1042\n",
      "Epoch 67/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7302 - loss: 0.6937 - val_accuracy: 0.6667 - val_loss: 1.0702\n",
      "Epoch 68/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7583 - loss: 0.6487 - val_accuracy: 0.6615 - val_loss: 1.0719\n",
      "Epoch 69/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7566 - loss: 0.6617 - val_accuracy: 0.6441 - val_loss: 1.1517\n",
      "Epoch 70/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7306 - loss: 0.7685 - val_accuracy: 0.6632 - val_loss: 1.0651\n",
      "Epoch 71/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7587 - loss: 0.6642 - val_accuracy: 0.6632 - val_loss: 1.0432\n",
      "Epoch 72/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7851 - loss: 0.5831 - val_accuracy: 0.6441 - val_loss: 1.0695\n",
      "Epoch 73/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7974 - loss: 0.5703 - val_accuracy: 0.6771 - val_loss: 1.0064\n",
      "Epoch 74/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7829 - loss: 0.6289 - val_accuracy: 0.6858 - val_loss: 1.0051\n",
      "Epoch 75/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7950 - loss: 0.5398 - val_accuracy: 0.6667 - val_loss: 1.0887\n",
      "Epoch 76/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8033 - loss: 0.5476 - val_accuracy: 0.6875 - val_loss: 1.0718\n",
      "Epoch 77/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7925 - loss: 0.5812 - val_accuracy: 0.7049 - val_loss: 1.0039\n",
      "Epoch 78/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7905 - loss: 0.5781 - val_accuracy: 0.7135 - val_loss: 1.0467\n",
      "Epoch 79/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8142 - loss: 0.5189 - val_accuracy: 0.7031 - val_loss: 1.0308\n",
      "Epoch 80/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8257 - loss: 0.4718 - val_accuracy: 0.7326 - val_loss: 0.9454\n",
      "Epoch 81/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8395 - loss: 0.4425 - val_accuracy: 0.7292 - val_loss: 0.9875\n",
      "Epoch 82/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8385 - loss: 0.4463 - val_accuracy: 0.7170 - val_loss: 1.0305\n",
      "Epoch 83/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8226 - loss: 0.5020 - val_accuracy: 0.7378 - val_loss: 1.0179\n",
      "Epoch 84/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8358 - loss: 0.4739 - val_accuracy: 0.7483 - val_loss: 0.9154\n",
      "Epoch 85/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8690 - loss: 0.3835 - val_accuracy: 0.7292 - val_loss: 1.0212\n",
      "Epoch 86/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8347 - loss: 0.4681 - val_accuracy: 0.7049 - val_loss: 1.1337\n",
      "Epoch 87/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8351 - loss: 0.4474 - val_accuracy: 0.7500 - val_loss: 0.9483\n",
      "Epoch 88/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8718 - loss: 0.3648 - val_accuracy: 0.7691 - val_loss: 0.9170\n",
      "Epoch 89/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8757 - loss: 0.3576 - val_accuracy: 0.7326 - val_loss: 1.0666\n",
      "Epoch 90/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8476 - loss: 0.4336 - val_accuracy: 0.7361 - val_loss: 0.9897\n",
      "Epoch 91/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.8393 - loss: 0.4431 - val_accuracy: 0.7622 - val_loss: 0.9993\n",
      "Epoch 92/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8719 - loss: 0.3446 - val_accuracy: 0.7865 - val_loss: 0.8836\n",
      "Epoch 93/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8768 - loss: 0.3555 - val_accuracy: 0.7639 - val_loss: 0.9890\n",
      "Epoch 94/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8464 - loss: 0.4273 - val_accuracy: 0.7622 - val_loss: 0.9933\n",
      "Epoch 95/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8957 - loss: 0.3223 - val_accuracy: 0.8056 - val_loss: 0.9109\n",
      "Epoch 96/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9092 - loss: 0.2597 - val_accuracy: 0.7917 - val_loss: 0.9545\n",
      "Epoch 97/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9088 - loss: 0.2764 - val_accuracy: 0.7622 - val_loss: 1.0353\n",
      "Epoch 98/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8799 - loss: 0.3905 - val_accuracy: 0.7899 - val_loss: 0.9154\n",
      "Epoch 99/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8979 - loss: 0.3043 - val_accuracy: 0.7934 - val_loss: 0.8851\n",
      "Epoch 100/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9147 - loss: 0.2734 - val_accuracy: 0.7587 - val_loss: 0.9013\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM Layer\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Fully connected Dense layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer (number of unique emotions)\n",
    "model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Reshape X_train and X_test for LSTM input\n",
    "X_train_lstm = X_train[..., np.newaxis]\n",
    "X_test_lstm = X_test[..., np.newaxis]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7507 - loss: 0.8984\n",
      "Test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_lstm, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'ravdess_emotion_recognition_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('ravdess_emotion_recognition_model.h5')\n",
    "print(\"Model saved as 'ravdess_emotion_recognition_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "The predicted emotion is: calm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the emotion labels dictionary (same as used during training)\n",
    "emotion_labels = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('ravdess_emotion_recognition_model.h5')\n",
    "\n",
    "# Initialize Label Encoder (used to encode the labels)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(emotion_labels.values()))\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_features(audio_path):\n",
    "    y_audio, sr = librosa.load(audio_path, sr=None)  # Load audio\n",
    "    mfccs = librosa.feature.mfcc(y=y_audio, sr=sr, n_mfcc=40)  # Extract MFCC features\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)  # Take mean of MFCCs\n",
    "    return mfccs_mean\n",
    "\n",
    "# Function to predict emotion\n",
    "def predict_emotion(audio_path):\n",
    "    # Extract MFCC features\n",
    "    features = extract_features(audio_path)\n",
    "\n",
    "    # Reshape the features for the model input (LSTM expects 3D input)\n",
    "    features_reshaped = np.expand_dims(features, axis=(0, 2))  # Shape: (1, number_of_features, 1)\n",
    "\n",
    "    # Predict using the model\n",
    "    predictions = model.predict(features_reshaped)\n",
    "    predicted_label = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Decode the predicted label to the corresponding emotion\n",
    "    predicted_emotion = label_encoder.inverse_transform(predicted_label)\n",
    "\n",
    "    return predicted_emotion[0]\n",
    "\n",
    "# Example usage\n",
    "audio_file_path = r'C:\\Users\\Hp\\Downloads\\RAVDESS\\Actor_01\\03-01-01-01-02-02-01.wav'\n",
    "predicted_emotion = predict_emotion(audio_file_path)\n",
    "print(f\"The predicted emotion is: {predicted_emotion}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
